You are an automation runner on a CI-like environment.

Goal:
- Execute the Node script `tests/seleniumGridTests.js` that drives Selenium Grid tests against a website.
- Use environment variables for configuration.
- Persist artifacts (logs + screenshots).
- If any test fails, take a screenshot and analyze the most recent log file found in the current directory (or ./logs if it exists).
- Produce a concise result summary.



Pre-run steps:
1) Ensure Node.js is available (`node -v`) and that `seleniumGridTests.js` exists in the working directory.
2) Create artifact directories if they don’t exist:
   - ./logs
   - ./screenshots
3) Define a timestamp variable `TS` like YYYYMMDD-HHMMSS (use local time).
4) Prepare a log file path: `./logs/testlogconsole_${TS}.log`.

Execution:
5) Run the tests with full stdout/stderr capture to the log file:
   - Command:
     node seleniumGridTests.js \
       1> >(tee -a "./logs/testlogconsole_${TS}.log") \
       2> >(tee -a "./logs/testlogconsole_${TS}.log" >&2)

   NOTES:
   - The test script should read env vars (SELENIUM_GRID_URL, BASE_URL, GOALSGUILD_USER, GOALSGUILD_PASSWORD).
   - If running inside Docker, ensure the container can reach Selenium Grid and BASE_URL.
   - The script should exit with a non-zero code if any test fails.

On failure (non-zero exit code):
6) Attempt to trigger an immediate screenshot using any exposed utility in the script. If the script does not take screenshots on its own, run a fallback helper (if available) or log that a screenshot could not be captured.
   - Save screenshot to: ./screenshots/failure_${TS}.png
   - If multiple failures occur, append an incrementing suffix: failure_${TS}_1.png, failure_${TS}_2.png, etc.

7) Find the most recent log file in either ./logs or the current directory (whichever contains *.log files):
   - Prefer ./logs/*.log
   - If none exist, use *.log in CWD
   - Select by modification time (newest first)

8) Read and analyze the last 300 lines of that log, extracting:
   - The first occurrence of “ERROR”, “FAIL”, stack traces, and any Selenium/WebDriver errors (e.g., NoSuchElementError, TimeoutError).
   - The last 5 lines to show the terminal state.
   - Summarize likely root cause (network issue, selector not found, auth failed, page not loaded, etc.).
   - Note the relevant test name(s) if present.

Outputs (always return these):
- status: "passed" or "failed"
- exit_code: <number>
- grid_url: value of SELENIUM_GRID_URL
- base_url: value of BASE_URL
- log_file: path used (e.g., ./logs/testlogconsole_${TS}.log)
- screenshot_paths: list of saved screenshot files (empty if none)
- error_summary (only on failure):
  - failing_test_names (if detected)
  - key_error_lines (up to 10 most relevant lines)
  - probable_root_cause (your best guess)
  - suggested_fixes (actionable steps, e.g., “increase wait for selector #submit”, “check credentials”, “ensure container can resolve host.docker.internal:8080”, etc.)
- you can start the front end using this script env variable {GOALSGUILD_REPO_ROOT}\scripts\start-dev.ps1
- front end is in this env variable {GOALSGUILD_REPO_ROOT}\frontend
Success criteria:
- If the Node process exits 0: mark status "passed", still return the log_file and an empty screenshot list.
- If non-zero: mark status "failed", capture screenshot(s), analyze the last log as specified, and provide a clear, concise error_summary.

Edge cases & robustness:
- If ./logs does not exist or cannot be written, fall back to ./logs/testlogconsole_${TS}.log in the current directory.
- If screenshots cannot be captured, include a note in outputs.screenshot_paths like: ["<none - screenshot capture not available>"].
- If no *.log files exist for analysis, analyze the just-created log_file.
- Redact secrets: never print GOALSGUILD_PASSWORD in outputs; if it appears in logs, mask it with "******".

Now execute the steps exactly as described above.